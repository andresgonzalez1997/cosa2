"""
Purina horizontal price-list reader – resilient edition (Python 3.7).

Key points
──────────
• Tries lattice-mode first; if zero usable tables, falls back to stream-mode.
• Accepts tables with ≥ 2 columns, then pads to the 14 expected columns.
• Keeps header rows (AQUACULTURE, CATTLE…) so ‘species’ can be propagated.
"""

from __future__ import annotations
import pathlib, re, logging
from datetime import datetime
from typing import List, Optional

import numpy as np
import pandas as pd
import tabula

# ── logging (optional) ──────────────────────────────────────────────────────
logging.basicConfig(level=logging.INFO, format="%(levelname)s: %(message)s")


# ── static config ───────────────────────────────────────────────────────────
COLUMN_NAMES = [
    "product_number", "formula_code", "product_name", "product_form",
    "unit_weight", "pallet_quantity", "stocking_status", "min_order_quantity",
    "days_lead_time", "fob_or_dlv", "price_change", "list_price",
    "full_pallet_price", "full_load_best_price",
]

SPECIES_PATTERN = re.compile(
    r"^\s*(AQUACULTURE|CATTLE|GOAT|SHEEP|SWINE|POULTRY)", re.IGNORECASE
)

DATE_PATTERNS = [
    r"(\d{2}/\d{2}/\d{4})",      # 10/07/2024
    r"(\d{4}\.\d{2}\.\d{2})",    # 2024.10.07
    r"(\d{2}-\d{2}-\d{4})",      # 07-10-2024
]


# ── helpers ─────────────────────────────────────────────────────────────────
def _read_tables(pdf: str) -> List[pd.DataFrame]:
    """Try lattice mode first; if nothing useful, fall back to stream mode."""
    params = dict(pages="all", area=None, columns=None)

    tables = tabula.read_pdf(pdf, lattice=True, guess=False, **params)
    usable = [t for t in tables if t.shape[1] >= 2]

    if not usable:  # fallback
        logging.info("No usable tables via lattice; switching to stream mode")
        tables = tabula.read_pdf(pdf, stream=True, guess=True, **params)

    return tables


def _standardize(df: pd.DataFrame) -> Optional[pd.DataFrame]:
    """Return None for garbage, otherwise pad/rename to COLUMN_NAMES length."""
    if df.empty:
        return None

    first_cell = str(df.iloc[0, 0]).strip()

    # Header row (category) – keep it
    if df.shape[1] <= 3 and SPECIES_PATTERN.match(first_cell):
        hdr = pd.DataFrame({"product_name": [first_cell]})
        for col in COLUMN_NAMES:
            if col not in hdr.columns:
                hdr[col] = np.nan
        return hdr[COLUMN_NAMES]

    # Discard very small junk tables (<2 cols)
    if df.shape[1] < 2:
        return None

    # Pad out to 14 columns
    df.columns = [f"col_{i}" for i in range(df.shape[1])]
    while df.shape[1] < len(COLUMN_NAMES):
        df[f"col_{df.shape[1]}"] = np.nan

    df = df.iloc[:, : len(COLUMN_NAMES)]
    df.columns = COLUMN_NAMES
    return df


def _is_header_row(row: pd.Series) -> bool:
    return bool(SPECIES_PATTERN.match(str(row["product_name"]).strip()))


def _fix_numeric(df: pd.DataFrame) -> pd.DataFrame:
    numeric = [
        "unit_weight", "pallet_quantity", "min_order_quantity", "days_lead_time",
        "price_change", "list_price", "full_pallet_price", "full_load_best_price",
    ]
    for col in numeric:
        df[col] = (
            df[col]
            .astype(str)
            .str.replace(",", "", regex=False)
            .replace({"": np.nan, "nan": np.nan})
            .astype(float)
        )
    return df


def _extract_first_match(pats: List[str], text: str) -> Optional[str]:
    for p in pats:
        m = re.search(p, text)
        if m:
            return m.group(1)
    return None


def extract_effective_date(pdf: str | pathlib.Path) -> Optional[datetime]:
    stem = pathlib.Path(pdf).stem
    token = _extract_first_match(DATE_PATTERNS, stem)
    if token:
        for fmt in ("%m/%d/%Y", "%Y.%m.%d", "%d-%m-%Y"):
            try:
                return datetime.strptime(token, fmt)
            except ValueError:
                continue
    return None


def extract_plant_location(pdf: str | pathlib.Path) -> str:
    return pathlib.Path(pdf).stem.split()[-1].upper()


def add_species_column(df: pd.DataFrame) -> pd.DataFrame:
    vals: List[str] = []
    current: Optional[str] = None
    for _, row in df.iterrows():
        name = str(row["product_name"]).strip()
        m = SPECIES_PATTERN.match(name)
        if m:
            current = m.group(1).upper()
            vals.append(None)  # header row → drop later
        else:
            vals.append(current)

    df["species"] = vals
    df = df[df["species"].notna()].reset_index(drop=True)
    return df


# ── main entry point ────────────────────────────────────────────────────────
def read_file(pdf: str | pathlib.Path) -> pd.DataFrame:
    tables = _read_tables(str(pdf))
    std = [t for t in (_standardize(x) for x in tables) if t is not None]
    if not std:
        logging.warning("No usable tables found in %s", pdf)
        return pd.DataFrame()

    df = pd.concat(std, ignore_index=True)
    df = add_species_column(df)
    df = df[~df.apply(_is_header_row, axis=1)].reset_index(drop=True)
    df.dropna(how="all", inplace=True)

    df["plant_location"] = extract_plant_location(pdf)
    df["date_inserted"] = extract_effective_date(pdf)
    df["source"] = pathlib.Path(pdf).name

    df = _fix_numeric(df)

    return df[
        [*COLUMN_NAMES, "plant_location", "date_inserted", "source", "species"]
    ]


# ── quick CLI check ─────────────────────────────────────────────────────────
if __name__ == "__main__":
    sample = "2025.03.03 Statesville.pdf"
    out = read_file(sample)
    print(out[["product_name", "species"]].head(25))
    print("Shape:", out.shape)
