-----
"""
purina_file_horizontal.py  – versión compatible con Python 3.7 (CDSW)

• Limpia listas de precio Purina (formato horizontal) y entrega un único
  DataFrame con:
      16 columnas estándar
      + plant_location
      + date_inserted
      + source
      + species (encabezado de cada sección, propagado a sus filas)
"""

from __future__ import annotations   # PEP-563 (funciona en 3.7)
import datetime as _dt
import pathlib
import re
from typing import List, Optional, Union

import pandas as pd
import tabula
from PyPDF2 import PdfReader


# --------------------------------------------------------------------------- #
# 1. Nombres estándar (16 columnas del PDF)                                   #
# --------------------------------------------------------------------------- #
COLUMN_NAMES: List[str] = [
    "product_number",
    "formula_code",
    "product_name",
    "product_form",
    "unit_weight",
    "pallet_quantity",
    "stocking_status",
    "min_order_quantity",
    "days_lead_time",
    "fob_or_dlv",
    "price_change",
    "list_price",
    "full_pallet_price",
    "half_load_full_pallet_price",
    "full_load_full_pallet_price",
    "full_load_best_price",
]

# --------------------------------------------------------------------------- #
# 2. Columnas que deben ser float                                             #
# --------------------------------------------------------------------------- #
NUMERIC_COLS: List[str] = (
    ["pallet_quantity", "min_order_quantity", "days_lead_time"]
    + COLUMN_NAMES[10:]
)

# --------------------------------------------------------------------------- #
# 3. Regex de fecha y planta                                                  #
# --------------------------------------------------------------------------- #
_DATE_PATTERNS = [
    re.compile(r'(\d{1,2}[/-]\d{1,2}[/-]\d{2,4})\s*Effective\s+Date', re.I),
    re.compile(r'Effective\s+Date\s*[-–—]?\s*(\d{1,2}[/-]\d{1,2}[/-]\d{2,4})', re.I),
]


def extract_effective_date(pdf_path: Union[str, pathlib.Path]) -> _dt.date:
    """Devuelve la fecha efectiva como datetime.date."""
    reader = PdfReader(str(pdf_path))
    first_page_text = reader.pages[0].extract_text()

    for rx in _DATE_PATTERNS:
        m = rx.search(first_page_text)
        if m:
            date_str = m.group(1)                 # ej.: 03-03-2025
            sep = "/" if "/" in date_str else "-"
            mm, dd, yy = date_str.split(sep)
            if len(yy) == 2:                      # normaliza año 2-dígitos
                yy = "20" + yy
            return _dt.datetime.strptime(
                f"{mm}{sep}{dd}{sep}{yy}", f"%m{sep}%d{sep}%Y"
            ).date()

    raise ValueError("No se encontró la fecha efectiva en el PDF.")


def extract_plant_location(pdf_path: Union[str, pathlib.Path]) -> str:
    """Extrae 'STATESVILLE NC', etc., desde la cabecera."""
    try:
        tables = tabula.read_pdf(
            pdf_path,
            pages=1,
            area=[0, 650, 60, 1000],
            lattice=False,
            guess=False,
            pandas_options={"header": None, "dtype": str},
        )
        if not tables:
            return "PLANTA DESCONOCIDA"

        text = " ".join(tables[0].fillna("").values.flatten())
        m = re.search(r"-\s*([A-Za-z &.\-]+?)\s+([A-Za-z]{2})\b", text)
        if m:
            city, state = m.groups()
            return f"{city.strip().upper()} {state.upper()}"
        return "PLANTA DESCONOCIDA"
    except Exception:
        return "PLANTA DESCONOCIDA"


# --------------------------------------------------------------------------- #
# 4. Lectura de todas las tablas del PDF                                      #
# --------------------------------------------------------------------------- #
def _read_tables(pdf_path: Union[str, pathlib.Path]):
    try:
        return tabula.read_pdf(
            pdf_path,
            pages="all",
            lattice=True,
            guess=False,
            pandas_options={"dtype": str, "header": None},
        )
    except Exception as exc:
        print("[tabula]", exc)
        return []


# --------------------------------------------------------------------------- #
# 5. Normalización a 16 columnas                                              #
# --------------------------------------------------------------------------- #
def _standardize(tbl: pd.DataFrame) -> Optional[pd.DataFrame]:
    # Elimina columnas vacías al final
    while tbl.shape[1] > 0 and tbl.iloc[:, -1].isna().all():
        tbl = tbl.iloc[:, :-1]

    if tbl.shape[1] < 16:
        return None

    # Si sobran columnas, busca la mejor ventana de 16
    if tbl.shape[1] > 16:
        best_start, best_score = 0, -1
        row0 = tbl.iloc[0].astype(str)

        for start in range(tbl.shape[1] - 15):
            slice_ = row0.iloc[start:start + 16]
            score = slice_.str.replace(",", "").str.strip() \
                           .str.match(r"^-?[\d.]+$").sum()
            if score > best_score:
                best_start, best_score = start, score

        tbl = tbl.iloc[:, best_start:best_start + 16]

    tbl.columns = COLUMN_NAMES
    return tbl


# --------------------------------------------------------------------------- #
# 6. Conversión segura a float                                                #
# --------------------------------------------------------------------------- #
def _to_float(val):
    if pd.isna(val):
        return None
    s = str(val).replace(",", "").strip()
    sign = -1 if s.endswith("-") or (s.startswith("(") and s.endswith(")")) else 1
    s = s.strip("()- ")
    try:
        return float(s) * sign
    except ValueError:
        return None


def _fix_numeric(df: pd.DataFrame) -> pd.DataFrame:
    for col in NUMERIC_COLS:
        if col in df.columns:
            df[col] = df[col].apply(_to_float)
    return df


# --------------------------------------------------------------------------- #
# 7. Detección de filas-cabecera / fragmentos                                 #
# --------------------------------------------------------------------------- #
HEADER_TOKENS = {
    "PRODUCT", "FORM", "UNIT", "WEIGHT", "PALLET", "MIN", "ORDER",
    "QUANTITY", "DAYS", "LEAD", "TIME", "STOCKING", "STATUS", "FOB", "DLV",
}
_PRICE_RE = re.compile(
    "|".join(
        re.escape(p) for p in (
            "PRICE / UNIT", "PRICE IN US DOLLAR", "PRICE IN US DOLLARS",
            "MIN / DAYS", "FORMULA CODE", "MONTHLY", "PAGE",
        )
    ),
    re.I,
)


def _is_header_row(row: pd.Series) -> bool:
    txt = " ".join(row.astype(str)).upper()

    if _PRICE_RE.search(txt):
        return True

    first = str(row.iloc[0]).strip().upper()
    if "FORMULA" in txt and "PRODUCT" in txt:
        return True
    if first.startswith("PRODUCT") and str(row.iloc[1]).upper().startswith("FORMULA"):
        return True
    if pd.isna(row["list_price"]) and any(tok in txt for tok in HEADER_TOKENS):
        return True

    return False


# --------------------------------------------------------------------------- #
# 8. Extrae la especie (species)                                              #
# --------------------------------------------------------------------------- #
def _grab_species(tbl: pd.DataFrame):
    """
    Retorna (species, tabla_sin_fila_species).  Se toma la primera fila
    que no contenga dígitos (probable título de sección).
    """
    for idx, row in tbl.iterrows():
        joined = " ".join(row.fillna("").astype(str)).strip()
        if joined and not any(ch.isdigit() for ch in joined):
            species = joined.upper()
            tbl = tbl.drop(idx).reset_index(drop=True)
            return species, tbl
    return None, tbl


# --------------------------------------------------------------------------- #
# 9. FUNCIÓN PRINCIPAL                                                        #
# --------------------------------------------------------------------------- #
def read_file(pdf_path: Union[str, pathlib.Path]) -> pd.DataFrame:
    """
    Procesa un PDF horizontal y devuelve un DataFrame con:
        16 columnas estándar + metadatos + species
    """
    raw_tables = _read_tables(pdf_path)
    if not raw_tables:
        return pd.DataFrame()

    clean_tables = []
    last_species = None

    for raw_tbl in raw_tables:
        species, raw_tbl = _grab_species(raw_tbl)
        if species is not None:
            last_species = species
        else:
            species = last_species  # propaga la última conocida

        std_tbl = _standardize(raw_tbl)
        if std_tbl is None:
            continue

        std_tbl = std_tbl[~std_tbl.apply(_is_header_row, axis=1)].reset_index(drop=True)
        std_tbl.dropna(how="all", inplace=True)

        if std_tbl.empty:
            continue

        std_tbl["species"] = species
        clean_tables.append(std_tbl)

    if not clean_tables:
        return pd.DataFrame()

    df = pd.concat(clean_tables, ignore_index=True)
    df = _fix_numeric(df)

    # Metadatos finales
    df["plant_location"] = extract_plant_location(pdf_path)
    df["date_inserted"] = extract_effective_date(pdf_path)
    df["source"] = pathlib.Path(pdf_path).name

    return df[[*COLUMN_NAMES, "plant_location", "date_inserted",
               "source", "species"]]
