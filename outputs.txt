"""
Purina – Horizontal price-list reader & cleaner (Python 3.7).

Flow
────
1. Read every table in the PDF with tabula-py.
2. Standardise each table to the expected 14 columns.
3. Preserve section headers (AQUACULTURE, CATTLE …) so we can
   propagate the new ‘species’ column downwards.
4. Drop those header rows once species has been filled.
5. Fix numeric types, add file-level metadata, return tidy DataFrame.
"""

from __future__ import annotations

import pathlib
import re
from datetime import datetime
from typing import List, Optional

import numpy as np
import pandas as pd
import tabula

# ── 1. Static config ────────────────────────────────────────────────────────

COLUMN_NAMES = [
    "product_number",
    "formula_code",
    "product_name",
    "product_form",
    "unit_weight",
    "pallet_quantity",
    "stocking_status",
    "min_order_quantity",
    "days_lead_time",
    "fob_or_dlv",
    "price_change",
    "list_price",
    "full_pallet_price",
    "full_load_best_price",
]

TABULA_OPTIONS = {
    "pages": "all",
    "guess": False,
    "lattice": True,
    "area": None,
    "columns": None,
}

# Matches “AQUACULTURE”, “CATTLE …”, “POULTRY” … at start of line
SPECIES_PATTERN = re.compile(
    r"^\s*(AQUACULTURE|CATTLE|GOAT|SHEEP|SWINE|POULTRY)", re.IGNORECASE
)

DATE_PATTERNS = [
    r"(\d{2}/\d{2}/\d{4})",     # 10/07/2024
    r"(\d{4}\.\d{2}\.\d{2})",   # 2024.10.07
    r"(\d{2}-\d{2}-\d{4})",     # 07-10-2024
]

# ── 2. Helpers ──────────────────────────────────────────────────────────────


def _read_tables(pdf_path: str) -> List[pd.DataFrame]:
    return tabula.read_pdf(pdf_path, **TABULA_OPTIONS)


def _standardize(df: pd.DataFrame) -> Optional[pd.DataFrame]:
    """
    • Keep header-only tables (≤ 3 cols) so we can read the species.
    • Accept data tables with ≥ 3 cols and pad them out to 14.
    • Discard anything smaller than 3 cols that isn’t a header.
    """
    if df.empty:
        return None

    first_cell = str(df.iloc[0, 0]).strip()

    # Header row – becomes a single-row table with just product_name filled
    if df.shape[1] <= 3 and SPECIES_PATTERN.match(first_cell):
        header = pd.DataFrame({"product_name": [first_cell]})
        for col in COLUMN_NAMES:
            if col not in header.columns:
                header[col] = np.nan
        return header[COLUMN_NAMES]

    # Real tables: need at least 3 meaningful columns
    if df.shape[1] < 3:
        return None

    # Generic column names, then pad to full width
    df.columns = [f"col_{i}" for i in range(df.shape[1])]
    while df.shape[1] < len(COLUMN_NAMES):
        df[f"col_{df.shape[1]}"] = np.nan

    df = df.iloc[:, : len(COLUMN_NAMES)]
    df.columns = COLUMN_NAMES
    return df


def _is_header_row(row: pd.Series) -> bool:
    return bool(SPECIES_PATTERN.match(str(row["product_name"]).strip()))


def _fix_numeric(df: pd.DataFrame) -> pd.DataFrame:
    numeric = [
        "unit_weight",
        "pallet_quantity",
        "min_order_quantity",
        "days_lead_time",
        "price_change",
        "list_price",
        "full_pallet_price",
        "full_load_best_price",
    ]
    for col in numeric:
        df[col] = (
            df[col]
            .astype(str)
            .str.replace(",", "", regex=False)
            .replace({"": np.nan, "nan": np.nan})
            .astype(float)
        )
    return df


def _extract_first_match(patterns: List[str], text: str) -> Optional[str]:
    for pat in patterns:
        m = re.search(pat, text)
        if m:
            return m.group(1)
    return None


def extract_effective_date(pdf_path: str | pathlib.Path) -> Optional[datetime]:
    stem = pathlib.Path(pdf_path).stem
    token = _extract_first_match(DATE_PATTERNS, stem)
    if token:
        for fmt in ("%m/%d/%Y", "%Y.%m.%d", "%d-%m-%Y"):
            try:
                return datetime.strptime(token, fmt)
            except ValueError:
                continue
    return None


def extract_plant_location(pdf_path: str | pathlib.Path) -> str:
    return pathlib.Path(pdf_path).stem.split()[-1].upper()


# ── 3. Species propagation ──────────────────────────────────────────────────


def add_species_column(df: pd.DataFrame) -> pd.DataFrame:
    species_vals: List[str] = []
    current: Optional[str] = None

    for _, row in df.iterrows():
        name = str(row["product_name"]).strip()
        m = SPECIES_PATTERN.match(name)
        if m:
            current = m.group(1).upper()   # capture group → AQUACULTURE …
            species_vals.append(None)      # header row → drop later
        else:
            species_vals.append(current)

    df["species"] = species_vals
    df = df[df["species"].notna()].reset_index(drop=True)
    return df


# ── 4. Main entry point ─────────────────────────────────────────────────────


def read_file(pdf: str | pathlib.Path) -> pd.DataFrame:
    tables = _read_tables(str(pdf))
    std = [t for t in (_standardize(x) for x in tables) if t is not None]
    if not std:
        return pd.DataFrame()

    df = pd.concat(std, ignore_index=True)
    df = add_species_column(df)                       # 1 propagate species
    df = df[~df.apply(_is_header_row, axis=1)].reset_index(drop=True)
    df.dropna(how="all", inplace=True)

    # File-level metadata
    df["plant_location"] = extract_plant_location(pdf)
    df["date_inserted"] = extract_effective_date(pdf)
    df["source"] = pathlib.Path(pdf).name

    df = _fix_numeric(df)

    return df[
        [*COLUMN_NAMES, "plant_location", "date_inserted", "source", "species"]
    ]


# ── 5. Quick CLI test ───────────────────────────────────────────────────────
if __name__ == "__main__":
    demo = read_file("2025.03.03 Statesville.pdf")
    print(demo[["product_name", "species"]].head(25))
    print("Shape:", demo.shape)
