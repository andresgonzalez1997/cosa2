#........................
"""
Lectura y limpieza de PDFs (formato horizontal Purina).

• Conservar la primera línea real de datos de cada página.
• Eliminar cabeceras repetidas ("PRODUCT NUMBER …"), fragmentos ("MIN / DAYS")
  y textos sueltos como "Price / Unit".
• Corrige números negativos (100-  →  -100) y añade metadatos (fecha, planta).
• **NUEVO** ▸ agrega columna «species» tomando el título de cada bloque.
• Uso:  df = read_file("2025.03.03 Statesville.pdf")  # DataFrame final
"""
from __future__ import annotations

import datetime as _dt
import pathlib
import re
from typing import List, Optional, Tuple

import pandas as pd
import tabula
from PyPDF2 import PdfReader

# --------------------------------------------------------------------------- #
# 1. Columnas estándar (16 que vienen en el PDF)                              #
# --------------------------------------------------------------------------- #
COLUMN_NAMES: List[str] = [
    "product_number", "formula_code", "product_name", "product_form",
    "unit_weight", "pallet_quantity", "stocking_status", "min_order_quantity",
    "days_lead_time", "fob_or_dlv", "price_change", "list_price",
    "full_pallet_price", "half_load_full_pallet_price",
    "full_load_full_pallet_price", "full_load_best_price",
]

# --------------------------------------------------------------------------- #
# 2. Listado completo de categorías (species)                                 #
# --------------------------------------------------------------------------- #
SPECIES_LIST = [
    "AQUACULTURE",
    "CATTLE - ACCURATION/SPR BLOCKS",
    "CATTLE - PROTEIN TUBS",
    "CATTLE - MINERAL TUBS",
    "CATTLE - WEATHERIZED MINERAL",
    "CATTLE - STARTERS",
    "CATTLE - FINISHERS",
    "CATTLE - RANGE SUPPLEMENTS",
    "SHEEP",
    "ALL PURPOSE LIVESTOCK",
    "DEER/GAME",
    "FAMILY FLOCK",
    "FAMILY FLOCK ORGANIC",
    "GAME BIRD",
    "GOAT",
    "GRAINLAND",
    "HORSE",
    "TRIPLE CROWN HORSE",
    "MAZURI BIRD/RATITE",
    "MAZURI HERBIVORE",
    "MAZURI KOI / AQUATIC",
    "MAZURI ALPACA/LLAMA",
    "MAZURI MINIPIG",
    "MAZURI OTHER",
    "MAZURI PRIMATE",
    "MAZURI RODENT",
    "MAZURI SMALL PACK",
    "SPECIALTY MILK REPLACERS",
    "MILK REPLACER - FULL POTENTIAL",
    "MILK REPLACER - GROWTH",
    "CALF CARE SUPPLEMENTS",
    "PET FOOD - EXCLUSIVE PRODUCTS",
    "PET FOOD - INFINIA PRODUCTS",
    "PET FOOD - RED FLANNEL",
    "PET FOOD - PMI TRADITIONAL",
    "RABBIT",
    "PREMIUM SHOW DIETS",
    "WILD BIRD",
    "SWINE RETAIL",
    "PLF CATTLE",
]
# Las normalizamos (mayúsculas y un solo espacio) para comparar rápidamente
SPECIES_SET = {re.sub(r"\s+", " ", s.upper().strip()) for s in SPECIES_LIST}

# --------------------------------------------------------------------------- #
# 3. Columnas numéricas que se convertirán a float                            #
# --------------------------------------------------------------------------- #
NUMERIC_COLS = [
    "pallet_quantity", "min_order_quantity", "days_lead_time",
    *COLUMN_NAMES[10:],   # todas las de precio
]

# --------------------------------------------------------------------------- #
# 4. Lectura de tablas con Tabula                                             #
# --------------------------------------------------------------------------- #
def _read_tables(pdf_path: str | pathlib.Path):
    """Lee todas las tablas en modo lattice; si falla, devuelve []."""
    try:
        return tabula.read_pdf(
            pdf_path,
            pages="all",
            lattice=True,
            guess=False,
            pandas_options={"dtype": str, "header": None},
        )
    except Exception as exc:
        print("[tabula]", exc)
        return []

# --------------------------------------------------------------------------- #
# 5. Normalización de cada tabla (recorta/desplaza)                           #
# --------------------------------------------------------------------------- #
def _standardize(tbl: pd.DataFrame) -> Optional[pd.DataFrame]:
    if tbl.shape[1] < 16:
        return None

    # Caso típico: 17 columnas (primer col = categoría o basura)
    if tbl.shape[1] >= 17:
        first, second = tbl.iloc[:, 0], tbl.iloc[:, 1]
        numeric_like = second.astype(str).str[0].str.isdigit().mean() > 0.5
        tbl = tbl.iloc[:, 1:17] if numeric_like else tbl.iloc[:, :16]
    else:
        tbl = tbl.iloc[:, :16]

    tbl.columns = COLUMN_NAMES
    return tbl

# --------------------------------------------------------------------------- #
# 6. Detección y propagación de «species»                                     #
# --------------------------------------------------------------------------- #
def _detect_species_in_row(values: List[str]) -> Optional[str]:
    """Devuelve la species si alguno de los valores **contiene** el texto."""
    joined = " ".join(str(v).upper().strip() for v in values if v and not pd.isna(v))
    joined = re.sub(r"\s+", " ", joined)
    for spec in SPECIES_SET:
        if spec in joined:
            return spec
    return None


def _attach_species(tbl: pd.DataFrame, last_species: Optional[str]) -> Tuple[pd.DataFrame, Optional[str]]:
    """
    ▸ Intenta detectar la especie en las primeras 3 filas (por si Tabula la ubica
      un poco más abajo).
    ▸ Si la encuentra, elimina esa fila y la usa; si no, hereda la anterior.
    ▸ Devuelve (tabla_sin_fila_categoria, species_detectada).
    """
    detected_species = None
    drop_idx = None

    for idx in range(min(3, len(tbl))):
        detected_species = _detect_species_in_row(tbl.iloc[idx].tolist())
        if detected_species:
            drop_idx = idx
            break

    if detected_species:
        tbl = tbl.drop(index=drop_idx).reset_index(drop=True)
        species_val = detected_species
    else:
        species_val = last_species  # hereda si no encontró nada

    tbl["species"] = species_val
    return tbl, species_val

# --------------------------------------------------------------------------- #
# 7. Conversión numérica puntual                                              #
# --------------------------------------------------------------------------- #
def _to_float(val):
    if pd.isna(val):
        return None
    s = str(val).replace(",", "").strip()
    sign = -1 if s.endswith("-") or (s.startswith("(") and s.endswith(")")) else 1
    s = s.strip("()- ")
    try:
        return float(s) * sign
    except ValueError:
        return None


def _fix_numeric(df: pd.DataFrame) -> pd.DataFrame:
    for col in NUMERIC_COLS:
        if col in df.columns:
            df[col] = df[col].apply(_to_float)
    return df

# --------------------------------------------------------------------------- #
# 8. Filtrado de filas-cabecera / fragmentos                                  #
# --------------------------------------------------------------------------- #
HEADER_TOKENS = {
    "PRODUCT", "FORM", "UNIT", "WEIGHT", "PALLET", "MIN", "ORDER", "QUANTITY",
    "DAYS", "LEAD", "TIME", "STOCKING", "STATUS", "FOB", "DLV",
}

PRICE_HEADER_PATTERNS = (
    "PRICE / UNIT",
    "PRICE IN US DOLLAR",
    "PRICE IN US DOLLARS",
    "MIN / DAYS",
    "FORMULA CODE",
    "MONTHLY",
    "PAGE",  # "Page 2 of 13"
)
_PRICE_RE = re.compile("|".join(re.escape(p) for p in PRICE_HEADER_PATTERNS), re.I)


def _is_header_row(row: pd.Series) -> bool:
    combined = " ".join(row.astype(str)).upper()
    if _PRICE_RE.search(combined):
        return True

    first = str(row.iloc[0]).strip().upper()
    if "FORMULA" in combined and "PRODUCT" in combined:
        return True
    if first and first[0].isdigit():
        return False  # fila de datos
    if first.startswith("PRODUCT") and str(row.iloc[1]).upper().startswith("FORMULA"):
        return True
    if pd.isna(row["list_price"]):
        if any(tok in combined for tok in HEADER_TOKENS):
            return True
    return False

# --------------------------------------------------------------------------- #
# 9. Extracción de FECHA EFECTIVA y PLANTA                                    #
# --------------------------------------------------------------------------- #
_DATE_PATTERNS = [
    re.compile(r"(\d{1,2}[/-]\d{1,2}[/-]\d{2,4})\s*Effective\s+Date", re.I),
    re.compile(r"Effective\s+Date\s*[-–—]?\s*(\d{1,2}[/-]\d{1,2}[/-]\d{2,4})", re.I),
]


def extract_effective_date(pdf_path: str | pathlib.Path) -> _dt.date:
    reader = PdfReader(str(pdf_path))
    first_page_text = reader.pages[0].extract_text()
    for rx in _DATE_PATTERNS:
        m = rx.search(first_page_text)
        if m:
            date_str = m.group(1)  # '01-06-2025' o '01/06/25'
            sep = "/" if "/" in date_str else "-"
            mm, dd, yy = date_str.split(sep)
            if len(yy) == 2:
                yy = "20" + yy
            return _dt.datetime.strptime(f"{mm}{sep}{dd}{sep}{yy}", f"%m{sep}%d{sep}%Y").date()
    raise ValueError("No se encontró la fecha efectiva en el PDF.")


def extract_plant_location(pdf_path: str | pathlib.Path) -> str:
    try:
        tables = tabula.read_pdf(
            pdf_path,
            pages=1,
            area=[0, 650, 60, 1000],  # franja donde suele aparecer
            lattice=False,
            guess=False,
            pandas_options={"header": None, "dtype": str},
        )
        if not tables:
            return "PLANTA DESCONOCIDA"
        text = " ".join(tables[0].fillna("").values.flatten())
        m = re.search(r"-\s*([A-Za-z &.\-]+?)\s+([A-Za-z]{2})\b", text)
        if m:
            plant, state = m.groups()
            return f"{plant.strip().upper()} {state.upper()}"
        return "PLANTA DESCONOCIDA"
    except Exception:
        return "PLANTA DESCONOCIDA"

# --------------------------------------------------------------------------- #
# 10. FUNCIÓN PRINCIPAL                                                       #
# --------------------------------------------------------------------------- #
def read_file(pdf: str | pathlib.Path) -> pd.DataFrame:
    """
    Procesa un PDF Purina horizontal y devuelve un DataFrame estandarizado
    con la columna «species» ya propagada.
    """
    raw_tables = _read_tables(str(pdf))
    if not raw_tables:
        return pd.DataFrame()

    processed_tables: List[pd.DataFrame] = []
    last_species = None

    for raw in raw_tables:
        std = _standardize(raw)
        if std is None:
            continue

        std, last_species = _attach_species(std, last_species)
        processed_tables.append(std)

    if not processed_tables:
        return pd.DataFrame()

    df = pd.concat(processed_tables, ignore_index=True)

    # Elimina cabeceras residuales
    df = df[~df.apply(_is_header_row, axis=1)].reset_index(drop=True)
    df.dropna(how="all", inplace=True)

    # Propaga species por si alguna tabla venía sin categoría explícita
    df["species"] = df["species"].ffill()

    # Metadatos
    df["plant_location"] = extract_plant_location(pdf)
    df["date_inserted"] = extract_effective_date(pdf)
    df["source"] = pathlib.Path(pdf).name

    df = _fix_numeric(df)

    # Orden final
    return df[[*COLUMN_NAMES, "plant_location", "date_inserted", "source", "species"]]
