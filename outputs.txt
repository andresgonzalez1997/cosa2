#...............
# purina_file_horizontal.py  – rev. 2025-05-07 (Python 3.7, CDSW)
from __future__ import annotations          # PEP-563 (string annotations)
import datetime as _dt
import pathlib
import re
from typing import List, Optional, Union

import pandas as pd
import tabula
from PyPDF2 import PdfReader


# ──────────────────────────────────────────────────────────────────────────────
# 1. Columnas estándar (16 originales del PDF)                                 
# ──────────────────────────────────────────────────────────────────────────────
COLUMN_NAMES: List[str] = [
    "product_number",
    "formula_code",
    "product_name",
    "product_form",
    "unit_weight",
    "pallet_quantity",
    "stocking_status",
    "min_order_quantity",
    "days_lead_time",
    "fob_or_dlv",
    "price_change",
    "list_price",
    "full_pallet_price",
    "half_load_full_pallet_price",
    "full_load_full_pallet_price",
    "full_load_best_price",
]

NUMERIC_COLS: List[str] = (
    ["pallet_quantity", "min_order_quantity", "days_lead_time"] +
    COLUMN_NAMES[10:]
)

# ──────────────────────────────────────────────────────────────────────────────
# 2. Regex para fecha y planta                                                  
# ──────────────────────────────────────────────────────────────────────────────
_DATE_PATTERNS = [
    re.compile(r'(\d{1,2}[/-]\d{1,2}[/-]\d{2,4})\s*Effective\s+Date', re.I),
    re.compile(r'Effective\s+Date\s*[-–—]?\s*(\d{1,2}[/-]\d{1,2}[/-]\d{2,4})', re.I),
]


def extract_effective_date(pdf_path: Union[str, pathlib.Path]) -> _dt.date:
    reader = PdfReader(str(pdf_path))
    page_txt = reader.pages[0].extract_text()

    for rx in _DATE_PATTERNS:
        m = rx.search(page_txt)
        if m:
            date_str = m.group(1)
            sep = "/" if "/" in date_str else "-"
            mm, dd, yy = date_str.split(sep)
            if len(yy) == 2:
                yy = "20" + yy
            return _dt.datetime.strptime(
                f"{mm}{sep}{dd}{sep}{yy}", f"%m{sep}%d{sep}%Y"
            ).date()
    raise ValueError("Fecha efectiva no encontrada.")


def extract_plant_location(pdf_path: Union[str, pathlib.Path]) -> str:
    try:
        tbls = tabula.read_pdf(
            pdf_path,
            pages=1,
            area=[0, 650, 60, 1000],
            lattice=False,
            guess=False,
            pandas_options={"header": None, "dtype": str},
        )
        if not tbls:
            return "PLANTA DESCONOCIDA"

        text = " ".join(tbls[0].fillna("").values.flatten())
        m = re.search(r"-\s*([\w &.\-]+?)\s+([A-Za-z]{2})\b", text)
        if m:
            city, state = m.groups()
            return f"{city.strip().upper()} {state.upper()}"
        return "PLANTA DESCONOCIDA"
    except Exception:
        return "PLANTA DESCONOCIDA"


# ──────────────────────────────────────────────────────────────────────────────
# 3. Lectura de todas las tablas con Tabula                                    
# ──────────────────────────────────────────────────────────────────────────────
def _read_tables(pdf_path: Union[str, pathlib.Path]):
    try:
        return tabula.read_pdf(
            pdf_path,
            pages="all",
            lattice=True,
            guess=False,
            pandas_options={"dtype": str, "header": None},
        )
    except Exception as exc:
        print("[tabula]", exc)
        return []


# ──────────────────────────────────────────────────────────────────────────────
# 4. Normaliza a 16 columnas (corrige traslapes)                               
# ──────────────────────────────────────────────────────────────────────────────
def _standardize(tbl: pd.DataFrame) -> Optional[pd.DataFrame]:
    # quita columnas 100 % vacías al final
    while tbl.shape[1] > 0 and tbl.iloc[:, -1].isna().all():
        tbl = tbl.iloc[:, :-1]

    if tbl.shape[1] < 16:
        return None

    if tbl.shape[1] > 16:
        best_start, best_score = 0, -1
        row0 = tbl.iloc[0].astype(str)
        for start in range(tbl.shape[1] - 15):
            slice_ = row0.iloc[start:start + 16]
            score = slice_.str.replace(",", "").str.strip() \
                           .str.match(r"^-?[\d.]+$").sum()
            if score > best_score:
                best_start, best_score = start, score
        tbl = tbl.iloc[:, best_start:best_start + 16]

    tbl.columns = COLUMN_NAMES
    return tbl


# ──────────────────────────────────────────────────────────────────────────────
# 5. Sanitizador numérico                                                     
# ──────────────────────────────────────────────────────────────────────────────
def _to_float(val):
    if pd.isna(val):
        return None
    s = str(val).replace(",", "").strip()
    sign = -1 if s.endswith("-") or (s.startswith("(") and s.endswith(")")) else 1
    s = s.strip("()- ")
    try:
        return float(s) * sign
    except ValueError:
        return None


def _fix_numeric(df: pd.DataFrame) -> pd.DataFrame:
    for col in NUMERIC_COLS:
        if col in df.columns:
            df[col] = df[col].apply(_to_float)
    return df


# ──────────────────────────────────────────────────────────────────────────────
# 6. Filtrado de filas cabecera / fragmentos                                  
# ──────────────────────────────────────────────────────────────────────────────
HEADER_TOKENS = {
    "PRODUCT", "FORM", "UNIT", "WEIGHT", "PALLET", "MIN", "ORDER", "QUANTITY",
    "DAYS", "LEAD", "TIME", "STOCKING", "STATUS", "FOB", "DLV",
}
_PRICE_RE = re.compile(
    "|".join(
        re.escape(p) for p in (
            "PRICE / UNIT", "PRICE IN US DOLLAR", "PRICE IN US DOLLARS",
            "MIN / DAYS", "FORMULA CODE", "MONTHLY", "PAGE",
        )
    ),
    re.I,
)


def _is_header_row(row: pd.Series) -> bool:
    txt = " ".join(row.astype(str)).upper()

    if _PRICE_RE.search(txt):
        return True

    first = str(row.iloc[0]).strip().upper()
    if "FORMULA" in txt and "PRODUCT" in txt:
        return True
    if first.startswith("PRODUCT") and str(row.iloc[1]).upper().startswith("FORMULA"):
        return True
    if pd.isna(row["list_price"]) and any(tok in txt for tok in HEADER_TOKENS):
        return True

    return False


# ──────────────────────────────────────────────────────────────────────────────
# 7. Propaga species y descarta filas-título repetidas                         
# ──────────────────────────────────────────────────────────────────────────────
def _assign_species(df: pd.DataFrame) -> pd.DataFrame:
    """
    Recorre el DataFrame y:
      • Detecta filas cuyo product_number es NaN o no inicia con dígito
        → las usa como nuevo 'species' y las descarta.
      • Propaga el species corriente a cada fila de datos real.
    """
    current = None
    keep_rows = []
    species_col = []

    for idx, row in df.iterrows():
        pn = str(row["product_number"]).strip()
        is_title = (pn == "") or (pn and not pn[0].isdigit())

        if is_title:
            joined = " ".join(row.fillna("").astype(str)).strip()
            if joined:        # actualiza especie y descarta la fila
                current = joined.upper()
            continue

        keep_rows.append(idx)
        species_col.append(current)

    df = df.loc[keep_rows].reset_index(drop=True)
    df["species"] = species_col
    return df


# ──────────────────────────────────────────────────────────────────────────────
# 8. FUNCIÓN PRINCIPAL                                                         
# ──────────────────────────────────────────────────────────────────────────────
def read_file(pdf_path: Union[str, pathlib.Path]) -> pd.DataFrame:
    """Devuelve DataFrame limpio con 20 columnas fijas."""
    raw_tables = _read_tables(pdf_path)
    if not raw_tables:
        return pd.DataFrame()

    data_frames = []

    for raw_tbl in raw_tables:
        std_tbl = _standardize(raw_tbl)
        if std_tbl is None:
            continue

        std_tbl = std_tbl[~std_tbl.apply(_is_header_row, axis=1)].reset_index(drop=True)
        std_tbl.dropna(how="all", inplace=True)
        if std_tbl.empty:
            continue

        std_tbl = _assign_species(std_tbl)
        data_frames.append(std_tbl)

    if not data_frames:
        return pd.DataFrame()

    df = pd.concat(data_frames, ignore_index=True)
    df = _fix_numeric(df)

    # metadatos
    df["plant_location"] = extract_plant_location(pdf_path)
    df["date_inserted"] = extract_effective_date(pdf_path)
    df["source"] = pathlib.Path(pdf_path).name

    # orden/selección final (descarta cualquier columna fantasma)
    final_cols = COLUMN_NAMES + [
        "plant_location",
        "date_inserted",
        "source",
        "species",
    ]
    return df.loc[:, final_cols]
