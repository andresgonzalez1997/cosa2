"""
Lectura y limpieza de PDFs Purina (horizontal).

Devuelve un DataFrame con 20 columnas:
16 de datos + plant_location + date_inserted + source + species
"""
from __future__ import annotations
import datetime as _dt
import pathlib
import re
from typing import List, Optional, Union

from PyPDF2 import PdfReader
import pandas as pd
import tabula

# --------------------------------------------------------------------------- #
# 1. Columnas estándar extraídas del PDF
# --------------------------------------------------------------------------- #
COLUMN_NAMES: List[str] = [
    "product_number",
    "formula_code",
    "product_name",
    "product_form",
    "unit_weight",
    "pallet_quantity",
    "stocking_status",
    "min_order_quantity",
    "days_lead_time",
    "fob_or_dlv",
    "price_change",
    "list_price",
    "full_pallet_price",
    "half_load_full_pallet_price",
    "full_load_full_pallet_price",
    "full_load_best_price",
]

# Columnas que deben ser numéricas (float) al final
NUMERIC_COLS: List[str] = [
    "pallet_quantity",
    "min_order_quantity",
    "days_lead_time",
    "price_change",
    "list_price",
    "full_pallet_price",
    "half_load_full_pallet_price",
    "full_load_full_pallet_price",
    "full_load_best_price",
]

# --------------------------------------------------------------------------- #
# 2. Metadatos: fecha efectiva y planta
# --------------------------------------------------------------------------- #
_DATE_PATTERNS = [
    re.compile(r"(\d{1,2}[/-]\d{1,2}[/-]\d{2,4})\s*Effective\s+Date", re.I),
    re.compile(r"Effective\s+Date\s*[-–—]?\s*(\d{1,2}[/-]\d{1,2}[/-]\d{2,4})", re.I),
]


def extract_effective_date(pdf_path: Union[str, pathlib.Path]) -> _dt.date:
    reader = PdfReader(str(pdf_path))
    txt = reader.pages[0].extract_text()
    for rx in _DATE_PATTERNS:
        m = rx.search(txt)
        if m:
            raw = m.group(1)
            sep = "/" if "/" in raw else "-"
            mm, dd, yy = raw.split(sep)
            if len(yy) == 2:
                yy = "20" + yy
            return _dt.datetime.strptime(f"{mm}{sep}{dd}{sep}{yy}", f"%m{sep}%d{sep}%Y").date()
    raise ValueError("Effective Date not found")


def extract_plant_location(pdf_path: Union[str, pathlib.Path]) -> str:
    try:
        tables = tabula.read_pdf(
            pdf_path,
            pages=1,
            area=[0, 650, 60, 1000],
            lattice=False,
            guess=False,
            pandas_options={"header": None, "dtype": str},
        )
        if not tables:
            return "UNKNOWN PLANT"
        text = " ".join(tables[0].fillna("").values.flatten())
        m = re.search(r"-\s*([A-Za-z &.\-]+?)\s+([A-Za-z]{2})\b", text)
        if m:
            plant, state = m.groups()
            return f"{plant.strip().upper()} {state.upper()}"
        return "UNKNOWN PLANT"
    except Exception:
        return "UNKNOWN PLANT"

# --------------------------------------------------------------------------- #
# 3. Lectura de tablas con Tabula
# --------------------------------------------------------------------------- #
def _read_tables(pdf_path: str):
    try:
        return tabula.read_pdf(
            pdf_path,
            pages="all",
            lattice=True,
            guess=False,
            pandas_options={"header": None, "dtype": str},
        )
    except Exception as exc:
        print("[tabula]", exc)
        return []

# --------------------------------------------------------------------------- #
# 4. Normalización de cada tabla
# --------------------------------------------------------------------------- #
def _standardize(tbl: pd.DataFrame) -> Optional[pd.DataFrame]:
    """
    Devuelve la tabla recortada a 16 columnas con nombres COLUMN_NAMES.
    Si hay ≥17 columnas, asume que la 1ª puede ser la categoría y la copia
    a product_name cuando la fila sea título.
    """
    if tbl.shape[1] < 16:
        return None

    if tbl.shape[1] >= 17:
        first = tbl.iloc[:, 0]
        core = tbl.iloc[:, -16:].copy()
        core.columns = COLUMN_NAMES
        hdr_mask = core["formula_code"].isna() & first.notna()
        core.loc[hdr_mask, "product_name"] = (
            first.loc[hdr_mask].astype(str).str.replace(",", "").str.strip()
        )
        tbl = core
    else:
        tbl = tbl.iloc[:, :16]
        tbl.columns = COLUMN_NAMES

    return tbl

# --------------------------------------------------------------------------- #
# 5. Conversión numérica segura
# --------------------------------------------------------------------------- #
def _to_float(x: str):
    if pd.isna(x):
        return None
    s = str(x).replace(",", "").strip()
    sign = -1 if s.endswith("-") or (s.startswith("(") and s.endswith(")")) else 1
    s = s.strip("()- ")
    try:
        return float(s) * sign
    except ValueError:
        return None


def _fix_numeric(df: pd.DataFrame) -> pd.DataFrame:
    for col in NUMERIC_COLS:
        if col in df.columns:
            df[col] = df[col].apply(_to_float)
    return df

# --------------------------------------------------------------------------- #
# 6. Filtrado de filas-cabecera/fragmentos (igual a tu versión original)
# --------------------------------------------------------------------------- #
HEADER_TOKENS = {
    "PRODUCT", "FORM", "UNIT", "WEIGHT", "PALLET",
    "MIN", "ORDER", "QUANTITY", "DAYS", "LEAD",
    "TIME", "STOCKING", "STATUS", "FOB", "DLV",
}

_PRICE_HDR_RE = re.compile(r"(PRICE\s*/\s*UNIT|PRICE IN US DOLLAR|MIN\s*/\s*DAYS)", re.I)


def _is_header_row(row: pd.Series) -> bool:
    combined = " ".join(row.astype(str)).upper()
    if _PRICE_HDR_RE.search(combined):
        return True

    first = str(row.iloc[0]).strip().upper()
    if first and first[0].isdigit():
        return False

    if pd.isna(row["list_price"]) and any(tok in combined for tok in HEADER_TOKENS):
        return True
    return False

# --------------------------------------------------------------------------- #
# 7. Propagar categoría → species
# --------------------------------------------------------------------------- #
def add_species_column(df: pd.DataFrame) -> pd.DataFrame:
    """
    Identifica la fila-título (sin precios >0 y product_number no numérico),
    propaga el texto a la columna `species` y elimina la fila-título.
    """
    price_cols = [
        "list_price", "full_pallet_price",
        "half_load_full_pallet_price", "full_load_full_pallet_price",
        "full_load_best_price",
    ]

    df["species"] = None
    current = None
    drop_idx = []

    for i, row in df.iterrows():
        price_sum = row[price_cols].apply(pd.to_numeric, errors="coerce").fillna(0).sum()
        pn_txt = str(row["product_number"]).strip()

        is_title = (price_sum == 0) and (pn_txt == "" or not pn_txt[0].isdigit())
        if is_title:
            # Primer texto no vacío de la fila
            title = next((str(v).strip() for v in row if str(v).strip()), "")
            current = title.upper()
            drop_idx.append(i)
        else:
            df.at[i, "species"] = current

    df.drop(index=drop_idx, inplace=True)
    df.reset_index(drop=True, inplace=True)
    return df

# --------------------------------------------------------------------------- #
# 8. Filtro de filas producto válidas
# --------------------------------------------------------------------------- #
def _is_valid_product(row: pd.Series) -> bool:
    pn_ok = pd.notna(row["product_number"]) and str(row["product_number"]).strip()[:1].isdigit()
    price_ok = pd.notna(row["list_price"])
    return pn_ok and price_ok

# --------------------------------------------------------------------------- #
# 9. Función principal
# --------------------------------------------------------------------------- #
def read_file(pdf: Union[str, pathlib.Path]) -> pd.DataFrame:
    tables = _read_tables(str(pdf))
    std = [t for t in (_standardize(x) for x in tables) if t is not None]
    if not std:
        return pd.DataFrame()

    df = pd.concat(std, ignore_index=True)

    # 1️⃣ Propaga species y remueve fila-título
    df = add_species_column(df)

    # 2️⃣ Limpia cabeceras/fragmentos
    df = df[~df.apply(_is_header_row, axis=1)].reset_index(drop=True)
    df = df[df.apply(_is_valid_product, axis=1)].reset_index(drop=True)
    df.dropna(how="all", inplace=True)

    # 3️⃣ Metadatos
    df["plant_location"] = extract_plant_location(pdf)
    df["date_inserted"] = extract_effective_date(pdf)
    df["source"] = pathlib.Path(pdf).name

    df = _fix_numeric(df)

    # Debug rápido (puedes comentar)
    print(">>> species muestras:", df["species"].dropna().unique()[:5])
    print(">>> filas con species:", df["species"].notna().sum())

    return df[[*COLUMN_NAMES, "plant_location", "date_inserted", "source", "species"]]

# --------------------------------------------------------------------------- #
# 10. Test rápido
# --------------------------------------------------------------------------- #
if __name__ == "__main__":
    import sys
    pdf_file = sys.argv[1]
    df_test = read_file(pdf_file)
    print(df_test.head())
