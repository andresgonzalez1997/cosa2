#-----------------------------------
"""
Lectura y limpieza de PDFs horizontales Purina.

● Conservar la primera línea real de datos.
● Eliminar cabeceras y fragmentos.
● Corregir números negativos y añadir metadatos.
● NUEVO: agrega la columna «species».

Función pública:
    df = read_file("archivo.pdf")      →   DataFrame con 20 columnas.
"""
from __future__ import annotations
import datetime as _dt
import pathlib
import re
from typing import List, Optional, Sequence

from PyPDF2 import PdfReader
import pandas as pd
import tabula


# ───────────────────────────────────────────────────────────────────────────────
# 1. Nombres estándar (16 columnas originales)
# ───────────────────────────────────────────────────────────────────────────────
COLUMN_NAMES: Sequence[str] = [
    "product_number", "formula_code", "product_name", "product_form",
    "unit_weight", "pallet_quantity", "stocking_status", "min_order_quantity",
    "days_lead_time", "fob_or_dlv", "price_change", "list_price",
    "full_pallet_price", "half_load_full_pallet_price",
    "full_load_full_pallet_price", "full_load_best_price",
]

# ───────────────────────────────────────────────────────────────────────────────
# 2. Columnas numéricas que se convertirán a float
# ───────────────────────────────────────────────────────────────────────────────
NUMERIC_COLS: List[str] = [
    "pallet_quantity", "min_order_quantity", "days_lead_time",
] + list(COLUMN_NAMES[10:])   # precios

# ───────────────────────────────────────────────────────────────────────────────
# 3. Lista blanca de categorías válidas
# ───────────────────────────────────────────────────────────────────────────────
ALL_SPECIES = [
    "AQUACULTURE", "CATTLE - ACCURATION/SPR BLOCKS", "CATTLE - PROTEIN TUBS",
    "CATTLE - MINERAL TUBS", "CATTLE - WEATHERIZED MINERAL", "CATTLE - STARTERS",
    "CATTLE - FINISHERS", "CATTLE - RANGE SUPPLEMENTS", "SHEEP",
    "ALL PURPOSE LIVESTOCK", "DEER/GAME", "FAMILY FLOCK", "FAMILY FLOCK ORGANIC",
    "GAME BIRD", "GOAT", "GRAINLAND", "HORSE", "TRIPLE CROWN HORSE",
    "MAZURI BIRD/RATITE", "MAZURI HERBIVORE", "MAZURI KOI / AQUATIC",
    "MAZURI ALPACA/LLAMA", "MAZURI MINIPIG", "MAZURI OTHER", "MAZURI PRIMATE",
    "MAZURI RODENT", "MAZURI SMALL PACK", "SPECIALTY MILK REPLACERS",
    "MILK REPLACER - FULL POTENTIAL", "MILK REPLACER - GROWTH",
    "CALF CARE SUPPLEMENTS", "PET FOOD - EXCLUSIVE PRODUCTS",
    "PET FOOD - INFINIA PRODUCTS", "PET FOOD - RED FLANNEL",
    "PET FOOD - PMI TRADITIONAL", "RABBIT", "PREMIUM SHOW DIETS", "WILD BIRD",
    "SWINE RETAIL", "PLF CATTLE",
]
_SPECIES_UP = [s.upper() for s in ALL_SPECIES]

# ───────────────────────────────────────────────────────────────────────────────
# 4. Metadatos: fecha efectiva y planta
# ───────────────────────────────────────────────────────────────────────────────
_DATE_PATTERNS = [
    re.compile(r'(\d{1,2}[/-]\d{1,2}[/-]\d{2,4})\s*Effective\s+Date', re.I),
    re.compile(r'Effective\s+Date\s*[-–—]?\s*(\d{1,2}[/-]\d{1,2}[/-]\d{2,4})', re.I),
]


def extract_effective_date(pdf_path: str | pathlib.Path) -> _dt.date:
    reader = PdfReader(str(pdf_path))
    first_page_text = reader.pages[0].extract_text()
    for rx in _DATE_PATTERNS:
        m = rx.search(first_page_text)
        if m:
            date_str = m.group(1)
            sep = "/" if "/" in date_str else "-"
            mm, dd, yy = date_str.split(sep)
            if len(yy) == 2:
                yy = "20" + yy
            return _dt.datetime.strptime(
                f"{mm}{sep}{dd}{sep}{yy}", f"%m{sep}%d{sep}%Y"
            ).date()
    raise ValueError("No se encontró la fecha efectiva.")


def extract_plant_location(pdf_path: str | pathlib.Path) -> str:
    try:
        tables = tabula.read_pdf(
            pdf_path, pages=1, area=[0, 650, 60, 1000],
            lattice=False, guess=False,
            pandas_options={"header": None, "dtype": str},
        )
        if not tables:
            return "PLANTA DESCONOCIDA"
        text = " ".join(tables[0].fillna("").values.flatten())
        m = re.search(r"-\s*([A-Za-z &.\-]+?)\s+([A-Za-z]{2})\b", text)
        if m:
            plant, state = m.groups()
            return f"{plant.strip().upper()} {state.upper()}"
        return "PLANTA DESCONOCIDA"
    except Exception:
        return "PLANTA DESCONOCIDA"

# ───────────────────────────────────────────────────────────────────────────────
# 5. Lectura de tablas
# ───────────────────────────────────────────────────────────────────────────────
def _read_tables(pdf):
    try:
        return tabula.read_pdf(
            pdf, pages="all", lattice=True, guess=False,
            pandas_options={"header": None, "dtype": str},
        )
    except Exception as exc:
        print("[tabula]", exc)
        return []

# ───────────────────────────────────────────────────────────────────────────────
# 6. Normalización de columnas
# ───────────────────────────────────────────────────────────────────────────────
def _standardize(tbl: pd.DataFrame) -> Optional[pd.DataFrame]:
    if tbl.shape[1] < 16:
        return None
    if tbl.shape[1] >= 17:
        first, second = tbl.iloc[:, 0], tbl.iloc[:, 1]
        numeric_like = second.astype(str).str[0].str.isdigit().mean() > 0.5
        tbl = tbl.iloc[:, 1:17] if numeric_like else tbl.iloc[:, :16]
    else:
        tbl = tbl.iloc[:, :16]
    tbl.columns = COLUMN_NAMES
    return tbl

# ───────────────────────────────────────────────────────────────────────────────
# 7. Conversión numérica
# ───────────────────────────────────────────────────────────────────────────────
def _to_float(s: str):
    if pd.isna(s):
        return None
    s = str(s).replace(",", "").strip()
    sign = -1 if s.endswith("-") or (s.startswith("(") and s.endswith(")")) else 1
    s = s.strip("()- ")
    try:
        return float(s) * sign
    except ValueError:
        return None


def _fix_numeric(df: pd.DataFrame) -> pd.DataFrame:
    for col in NUMERIC_COLS:
        if col in df.columns:
            df[col] = df[col].apply(_to_float)
    return df

# ───────────────────────────────────────────────────────────────────────────────
# 8. Filas-cabecera / fragmentos
# ───────────────────────────────────────────────────────────────────────────────
HEADER_TOKENS = {
    "PRODUCT", "FORM", "UNIT", "WEIGHT", "PALLET", "MIN", "ORDER",
    "QUANTITY", "DAYS", "LEAD", "TIME", "STOCKING", "STATUS", "FOB", "DLV",
}
_PRICE_RE = re.compile("|".join(map(re.escape, [
    "PRICE / UNIT", "PRICE IN US DOLLAR", "PRICE IN US DOLLARS", "MIN / DAYS",
    "FORMULA CODE", "MONTHLY", "PAGE",
])), re.I)


def _is_header_row(row: pd.Series) -> bool:
    combined = " ".join(row.astype(str)).upper()
    if _PRICE_RE.search(combined):
        return True
    first = str(row.iloc[0]).strip().upper()
    if (not first) or (first and not first[0].isdigit()):
        if any(tok in combined for tok in HEADER_TOKENS):
            return True
    if pd.isna(row["list_price"]) and any(tok in combined for tok in HEADER_TOKENS):
        return True
    return False

# ───────────────────────────────────────────────────────────────────────────────
# 9. Species
# ───────────────────────────────────────────────────────────────────────────────
def _normalize_species(raw: str) -> str:
    txt = re.sub(r"\s+", " ", str(raw).upper()).strip()
    for sp in _SPECIES_UP:
        if txt.startswith(sp):
            return ALL_SPECIES[_SPECIES_UP.index(sp)]
    return txt


def add_species_column(df: pd.DataFrame) -> pd.DataFrame:
    df["species"] = None
    current_species = None
    drop_idx = []

    for idx, row in df.iterrows():
        first_cell = str(row["product_number"]).strip() if pd.notna(row["product_number"]) else ""
        is_category = (first_cell == "") or (first_cell and not first_cell[0].isdigit())

        if is_category:
            for val in row:
                if pd.notna(val) and str(val).strip():
                    current_species = _normalize_species(val)
                    break
            drop_idx.append(idx)
        else:
            df.at[idx, "species"] = current_species

    df.drop(index=drop_idx, inplace=True)
    df.reset_index(drop=True, inplace=True)
    return df

# ───────────────────────────────────────────────────────────────────────────────
# 10. Función pública
# ───────────────────────────────────────────────────────────────────────────────
def read_file(pdf: str | pathlib.Path) -> pd.DataFrame:
    tables = _read_tables(str(pdf))
    std_tables = [t for t in (_standardize(x) for x in tables) if t is not None]
    if not std_tables:
        return pd.DataFrame()

    df = pd.concat(std_tables, ignore_index=True)
    df = add_species_column(df)
    df = df[~df.apply(_is_header_row, axis=1)].reset_index(drop=True)
    df.dropna(how="all", inplace=True)

    df["plant_location"] = extract_plant_location(pdf)
    df["date_inserted"] = extract_effective_date(pdf)
    df["source"] = pathlib.Path(pdf).name

    df = _fix_numeric(df)
    return df[[*COLUMN_NAMES, "plant_location", "date_inserted", "source", "species"]]

# ───────────────────────────────────────────────────────────────────────────────
# 11. Bloque de prueba rápido (SOLO imprime species)
# ───────────────────────────────────────────────────────────────────────────────
if __name__ == "__main__":
    import argparse
    import textwrap

    parser = argparse.ArgumentParser(
        description=textwrap.dedent(
            """
            Extrae las tablas de un PDF Purina horizontal y muestra la columna
            «species» para verificar su mapeo (no se genera ningún archivo).
            """
        )
    )
    parser.add_argument("pdf", help="Ruta al PDF a procesar")
    parser.add_argument("-n", "--rows", type=int, default=30,
                        help="Cuántas filas mostrar (default 30)")
    args = parser.parse_args()

    pdf_path = pathlib.Path(args.pdf)
    df_result = read_file(pdf_path)

    pd.set_option("display.max_columns", None)

    print("\n— Primeras filas con product_number y species —")
    print(df_result[["product_number", "species"]].head(args.rows))

    print("\n— Resumen de categorías encontradas —")
    print(df_result["species"].value_counts(dropna=False))

    print(f"\n✔ Procesado completo. Filas totales: {len(df_result):,}")
