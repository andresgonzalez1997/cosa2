"""
Purina horizontal PDF   →   DataFrame limpio (20 columnas)
-----------------------------------------------------------
• Detecta y propaga la categoría (AQUACULTURE, CATTLE – …) en `species`
• Elimina cabeceras de página, fragmentos y filas vacías
• Añade metadatos: plant_location, date_inserted, source
"""

from __future__ import annotations
import datetime as dt
import pathlib
import re
from typing import List, Optional, Union

import pandas as pd
import tabula
from PyPDF2 import PdfReader

# --------------------------------------------------------------------------- #
# 1. Columnas estándar (16 del PDF)
# --------------------------------------------------------------------------- #
COLUMN_NAMES: List[str] = [
    "product_number",
    "formula_code",
    "product_name",
    "product_form",
    "unit_weight",
    "pallet_quantity",
    "stocking_status",
    "min_order_quantity",
    "days_lead_time",
    "fob_or_dlv",
    "price_change",
    "list_price",
    "full_pallet_price",
    "half_load_full_pallet_price",
    "full_load_full_pallet_price",
    "full_load_best_price",
]

NUMERIC_COLS = [
    "pallet_quantity",
    "min_order_quantity",
    "days_lead_time",
    "price_change",
    "list_price",
    "full_pallet_price",
    "half_load_full_pallet_price",
    "full_load_full_pallet_price",
    "full_load_best_price",
]

# --------------------------------------------------------------------------- #
# 2. Metadatos: fecha y planta
# --------------------------------------------------------------------------- #
_DATE_PAT = re.compile(r"(\d{1,2}[/-]\d{1,2}[/-]\d{2,4})\s*Effective\s*Date", re.I)


def extract_effective_date(pdf: Union[str, pathlib.Path]) -> str:
    txt = PdfReader(str(pdf)).pages[0].extract_text()
    m = _DATE_PAT.search(txt)
    if not m:
        return ""
    raw = m.group(1)
    sep = "/" if "/" in raw else "-"
    mm, dd, yy = raw.split(sep)
    yy = "20" + yy if len(yy) == 2 else yy
    return f"{mm}{sep}{dd}{sep}{yy}"


def extract_plant_location(pdf: Union[str, pathlib.Path]) -> str:
    try:
        tbl = tabula.read_pdf(
            pdf,
            pages=1,
            area=[0, 650, 60, 1000],
            lattice=False,
            guess=False,
            pandas_options={"header": None, "dtype": str},
        )[0]
        text = " ".join(tbl.fillna("").values.flatten())
        m = re.search(r"-\s*([A-Za-z &.\-]+?)\s+([A-Za-z]{2})\b", text)
        return f"{m.group(1).strip().upper()} {m.group(2).upper()}" if m else ""
    except Exception:
        return ""

# --------------------------------------------------------------------------- #
# 3. Lectura de tablas
# --------------------------------------------------------------------------- #
def _read_tables(pdf):
    return tabula.read_pdf(
        pdf,
        pages="all",
        lattice=True,
        guess=False,
        pandas_options={"header": None, "dtype": str},
    )

# --------------------------------------------------------------------------- #
# 4. Normalizar cada tabla (16 últimas columnas)
# --------------------------------------------------------------------------- #
def _standardize(tbl: pd.DataFrame) -> Optional[pd.DataFrame]:
    if tbl.shape[1] < 16:
        return None
    core = tbl.iloc[:, -16:].copy()
    core.columns = COLUMN_NAMES
    return core

# --------------------------------------------------------------------------- #
# 5. Propagar categoría → species
# --------------------------------------------------------------------------- #
_TITLE_RE = re.compile(r"^[A-Z][A-Z0-9\s/&\-]{2,}$")


def _add_species(df: pd.DataFrame) -> pd.DataFrame:
    """
    • Encuentra la fila-título: sin precios (>0) y texto 100 % mayúsculas
      en su primera celda no-vacía.
    • Propaga con ffill() y elimina la fila-título.
    """
    price_cols = [
        "list_price",
        "full_pallet_price",
        "half_load_full_pallet_price",
        "full_load_full_pallet_price",
        "full_load_best_price",
    ]

    first_text = (
        df.fillna("")
          .apply(lambda r: next((v for v in r if str(v).strip()), ""), axis=1)
          .str.strip()
    )

    is_title = (
        first_text.str.fullmatch(_TITLE_RE).fillna(False) &
        (df[price_cols].fillna(0).apply(pd.to_numeric, errors="coerce").sum(axis=1) == 0)
    )

    df["species"] = None
    df.loc[is_title, "species"] = first_text[is_title].str.upper()
    df["species"] = df["species"].ffill()

    df = df[~is_title].reset_index(drop=True)
    return df

# --------------------------------------------------------------------------- #
# 6. Filtrar cabeceras/fragmentos
# --------------------------------------------------------------------------- #
_HEADER_TOKENS = {"PRODUCT", "FORM", "UNIT", "WEIGHT", "PALLET", "STOCKING", "STATUS"}


def _is_header(row: pd.Series) -> bool:
    combined = " ".join(row.astype(str)).upper()
    first = str(row.iloc[0]).strip()
    if first and not first[0].isdigit():
        if any(tok in combined for tok in _HEADER_TOKENS):
            return True
    return False

# --------------------------------------------------------------------------- #
# 7. Conversión numérica
# --------------------------------------------------------------------------- #
def _to_float(x):
    if pd.isna(x):
        return None
    s = str(x).replace(",", "").strip()
    sign = -1 if s.endswith("-") or (s.startswith("(") and s.endswith(")")) else 1
    s = s.strip("()- ")
    try:
        return float(s) * sign
    except ValueError:
        return None


def _fix_numeric(df: pd.DataFrame):
    for col in NUMERIC_COLS:
        df[col] = df[col].apply(_to_float)
    return df

# --------------------------------------------------------------------------- #
# 8. read_file principal
# --------------------------------------------------------------------------- #
def read_file(pdf: Union[str, pathlib.Path]) -> pd.DataFrame:
    tables = _read_tables(str(pdf))
    std = [t for t in (_standardize(x) for x in tables) if t is not None]
    if not std:
        return pd.DataFrame()

    df = pd.concat(std, ignore_index=True)

    # Propaga species y elimina fila-título
    df = _add_species(df)

    # Quita cabeceras de página
    df = df[~df.apply(_is_header, axis=1)].reset_index(drop=True)
    df.dropna(how="all", inplace=True)

    # Metadatos
    df["plant_location"] = extract_plant_location(pdf)
    df["date_inserted"] = extract_effective_date(pdf)
    df["source"] = pathlib.Path(pdf).name

    df = _fix_numeric(df)

    return df[[*COLUMN_NAMES, "plant_location", "date_inserted", "source", "species"]]

# --------------------------------------------------------------------------- #
# 9. Test rápido                                                             #
# --------------------------------------------------------------------------- #
if __name__ == "__main__":
    import sys
    pdf_path = sys.argv[1]
    frame = read_file(pdf_path)
    print(frame.head())
    print("Species únicos:", frame["species"].unique()[:10])
